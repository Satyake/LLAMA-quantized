{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (0.1.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (1.4.51)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (0.1.19)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp39-cp39-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp39-cp39-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB 1.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/14.5 MB 7.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 12.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.3/14.5 MB 16.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.5/14.5 MB 17.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.7/14.5 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.1/14.5 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.3/14.5 MB 19.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.5 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.4/14.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.4/14.5 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.0/14.5 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROMPT=\"You are a book summarizer and can provide updated summaries\"\n",
    "B_INST, E_INST=\"[INST]\", \"[/INST]\"\n",
    "B_SYS,E_SYS=\"<<SYS>>>\\n\", \"\\n<<<SYS>>>\\n\\n\"\n",
    "instruction=\"Convert the following text from english to french \\n\\n {text}\"\n",
    "\n",
    "instruction=\"Give a proper summary of the book of \\n\\n {text}\"\n",
    "SYSTEM_PROMPT=B_SYS+DEFAULT_PROMPT+E_SYS\n",
    "template=B_INST+SYSTEM_PROMPT+instruction+E_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST]<<SYS>>>\\nYou are a book summarizer and can provide updated summaries\\n<<<SYS>>>\\n\\nGive a proper summary of the book of \\n\\n {text}[/INST]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=template, input_variables=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model='llama-2-7b-chat.ggmlv3.q4_0.bin',\n",
    "                  model_type='llama',\n",
    "                  config={'max_new_tokens': 128,'temperature':0.01})\n",
    "llmchain=LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Certainly! Here is an updated summary of the book \"Harry Potter\" by J.K. Rowling:\n",
      "\n",
      "\"Harry Potter\" is a magical adventure that follows the journey of a young wizard named Harry Potter as he attends Hogwarts School of Witchcraft and Wizardry. Born to a poor but loving family, Harry discovers on his eleventh birthday that he is the son of two powerful wizards who were killed by the dark wizard Lord Voldemort.\n",
      "\n",
      "Harry begins his first year at Hogwarts, where\n"
     ]
    }
   ],
   "source": [
    "print(llmchain.run(\"Harry Potter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pdf=PyPDFDirectoryLoader('pdfs')\n",
    "loaded=data_pdf.load()\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "split_chunks=splitter.split_documents(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 116kB/s]\n",
      "c:\\Users\\satya\\anaconda3\\envs\\transformers\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\satya\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 17.8kB/s]\n",
      "README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 2.46MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 17.7kB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 184kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:01<00:00, 48.2MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 87.5kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 5.08MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 17.1MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 55.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                 model_kwargs={'device':'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=FAISS.from_documents(split_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model='llama-2-7b-chat.ggmlv3.q4_0.bin',\n",
    "                   model_type='llama',\n",
    "                   config={'max_new_tokens': 128,'temperature':0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROMPT=\"You are connected to a RAG system please use that to answer questions\"\n",
    "\n",
    "B_INST, E_INST=\"[INST]\", \"[/INST]\"\n",
    "B_SYS,E_SYS=\"<<SYS>>>\\n\", \"\\n<<<SYS>>>\\n\\n\"\n",
    "instruction=\"Please anwer questions {question} based on context {context} specific to the research paper \"\n",
    "\n",
    "SYSTEM_PROMPT=B_SYS+DEFAULT_PROMPT+E_SYS\n",
    "template=B_INST+SYSTEM_PROMPT+instruction+E_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST]<<SYS>>>\\nYou are connected to a RAG system please use that to answer questions\\n<<<SYS>>>\\n\\nPlease anwer questions {question} based on context {context} specific to the research paper [/INST]'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt=PromptTemplate(template=template,input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROMPT=\"Use the following pieces of information to answer the users question Context: {context} Question: {question} Answer in brief an objectively\"\n",
    "\n",
    "B_INST, E_INST=\"[INST]\", \"[/INST]\"\n",
    "B_SYS,E_SYS=\"<<SYS>>>\\n\", \"\\n<<<SYS>>>\\n\\n\"\n",
    "instruction=\"Can you tell me about the dataset used in the paper? \"\n",
    "\n",
    "SYSTEM_PROMPT=B_SYS+DEFAULT_PROMPT+E_SYS\n",
    "template=B_INST+SYSTEM_PROMPT+instruction+E_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROMPT=\"Use the following pieces of information to answer the users question Context: {context} Question: {question}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt=PromptTemplate(template=template,input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=RetrievalQA.from_chain_type(llm=llm,\n",
    "                                  chain_type='stuff',\n",
    "                                  retriever=vector_store.as_retriever(search_kwargs={'k':2}),\n",
    "                                  return_source_documents=True,\n",
    "                                  chain_type_kwargs={'prompt':qa_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input='what is the performance of the model on fall detection the author developed relating to Siamese networks?'\n",
    "result=chain({'query':user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is the performance of the model on fall detection the author developed relating to Siamese networks?', 'result': \"  RAG System:\\n\\nR - Recall: The model achieved an accuracy of 95% in detecting falls.\\nA - Precision: The model had a precision of 90% in identifying non-falls.\\nG - F1 Score: The model's F1 score for fall detection was 92%.\\n\\nBased on the context, Siamese networks are indeed effective in fall detection tasks. The novel network architecture developed in the research paper leverages the few examples available to learn and improve its performance over time. The use of Siamese networks allows the model\", 'source_documents': [Document(page_content='is paramount for fall detection.\\nSiamese networks are designed to learn from few examples', metadata={'source': 'pdfs\\\\IEEE_SENSORS_LETTERS.pdf', 'page': 0}), Document(page_content='A fall detection system (FEDS) using a novel Siamese network', metadata={'source': 'pdfs\\\\IEEE_SENSORS_LETTERS.pdf', 'page': 3})]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
